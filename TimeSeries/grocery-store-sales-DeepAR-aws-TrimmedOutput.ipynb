{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS SageMaker DeepAR on store sales forecasting\n",
    "\n",
    "For more information see the DeepAR [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html) or [paper](https://arxiv.org/abs/1704.04110), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VXdwkouzvCNr"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import zipfile\n",
    "from dateutil.parser import parse\n",
    "import json\n",
    "from random import shuffle\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "import s3fs\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import IntSlider, FloatSlider, Checkbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-ICV43TT1FP2"
   },
   "outputs": [],
   "source": [
    "# set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker_session = sagemaker.Session()\n",
    "sagemaker_session = sagemaker.Session(boto3.Session(region_name='us-east-1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.session.Session at 0x7f145b668c10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, we can override the default values for the following:\n",
    "- The S3 bucket and prefix to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = \"spring23-fts\"                    # Set a default S3 bucket\n",
    "# s3_bucket = sagemaker.Session.default_bucket()  # replace with an existing bucket if needed\n",
    "s3_prefix = \"deepar-exp\"  # prefix used for all data stored within the bucket\n",
    "\n",
    "role = sagemaker.get_execution_role()  # IAM role to use by SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://spring23-fts/deepar-exp/data\n",
      "s3://spring23-fts/deepar-exp/output\n",
      "us-east-1\n"
     ]
    }
   ],
   "source": [
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "s3_data_path = \"s3://{}/{}/data\".format(s3_bucket, s3_prefix)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(s3_bucket, s3_prefix)\n",
    "print(s3_data_path)\n",
    "print(s3_output_path)\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we configure the container image to be used for the region that we are running in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = sagemaker.image_uris.retrieve(\"forecasting-deepar\", region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and parse the dataset and convert it to a collection of Pandas time series, which makes common time series operations such as indexing by time periods or resampling much easier. Here we want to forecast longer periods (~two weeks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dictionary in json file\n",
    "def write_dicts_to_file(path, data):\n",
    "  with open(path, \"wb\") as fp:\n",
    "      for d in data:\n",
    "          fp.write(json.dumps(d).encode(\"utf-8\"))\n",
    "          fp.write(\"\\n\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_skip = ['id','evt_type', 'evt_locale', 'evt_desc', 'evt_desc_gran', 'evt_selected', 'imp_event', 'imp_evt_enc']\n",
    "train_path = 's3://{}/{}'.format(s3_bucket, \"train_cleaned_crs.csv\")\n",
    "test_path = 's3://{}/{}'.format(s3_bucket, \"test_cleaned_crs.csv\")\n",
    "\n",
    "def prepare_data(train_path, test_path, columns_to_skip, out_path, out_sf_path,\n",
    "                 process_test = False, use_rows = None, min_day = -1):\n",
    "  if process_test:\n",
    "    df = pd.concat([\n",
    "        pd.read_csv(\n",
    "            train_path,\n",
    "            usecols=lambda x: x not in columns_to_skip,\n",
    "            dtype={\n",
    "                \"store_nbr\": \"category\", \"family\": \"category\",\n",
    "                \"store_type\": \"category\", \"cluster\": \"category\",\n",
    "                \"city\": \"category\", \"state\": \"category\"\n",
    "            },\n",
    "            nrows = use_rows,\n",
    "            index_col=['date'], parse_dates=['date']\n",
    "        ),\n",
    "        pd.read_csv(\n",
    "            test_path,\n",
    "            usecols=lambda x: x not in columns_to_skip,\n",
    "            dtype={\n",
    "                \"store_nbr\": \"category\", \"family\": \"category\",\n",
    "                \"store_type\": \"category\", \"cluster\": \"category\",\n",
    "                \"city\": \"category\", \"state\": \"category\"\n",
    "            },\n",
    "            nrows = use_rows,\n",
    "            index_col=['date'], parse_dates=['date']\n",
    "        )\n",
    "    ])\n",
    "  else:\n",
    "    df = pd.read_csv(        \n",
    "        train_path,\n",
    "        usecols=lambda x: x not in columns_to_skip,\n",
    "        dtype={\n",
    "            \"store_nbr\": \"category\", \"family\": \"category\",\n",
    "            \"store_type\": \"category\", \"cluster\": \"category\",\n",
    "            \"city\": \"category\", \"state\": \"category\"\n",
    "        },\n",
    "        nrows = use_rows,\n",
    "        index_col=['date'], parse_dates=['date']\n",
    "      )\n",
    "\n",
    "  # store - family combo in training\n",
    "  st_fm = (\n",
    "      df\n",
    "      .value_counts(['store_nbr', 'family'], ascending=True)\n",
    "      .reset_index()\n",
    "      .rename(columns={0: \"days\"})\n",
    "  )\n",
    "  if process_test:\n",
    "    st_fm[st_fm.days > min_day].to_csv(out_sf_path)\n",
    "\n",
    "  # role of variables\n",
    "  target_col = \"sales\"\n",
    "  cat_cols = [\"store_nbr\", \"family\", \"store_type\", \"cluster\", \"city\", \"state\"]\n",
    "  feat_cols = (\n",
    "      [\"first_jan\", \"liquor_sunday\", \"onpromotion_log\", \"crs_str_prm_rat\", \"dcoilwtico\"]\n",
    "      + [c for c in df.columns if (\"onpromotion_log_\" in c) or (\"evt_sel_hot_\" in c)]\n",
    "  )\n",
    "  # Store the data in json format as required by AWS DeepAR\n",
    "  out_data = [\n",
    "      {\n",
    "          \"start\": str(min(df[(df.store_nbr==s)&(df.family==f)].index)),\n",
    "          \"target\": np.log1p(df[(df.store_nbr==s)&(df.family==f)][target_col].dropna()).tolist(),\n",
    "          \"dynamic_feat\": [df[(df.store_nbr==s)&(df.family==f)][x].tolist() for x in feat_cols],\n",
    "          \"cat\": [int(df[(df.store_nbr==s)&(df.family==f)][x].cat.codes[0]) for x in cat_cols],\n",
    "      }\n",
    "      for (s,f) in zip(\n",
    "          st_fm[st_fm.days > min_day].store_nbr[:],\n",
    "          st_fm[st_fm.days > min_day].family[:]\n",
    "      )\n",
    "  ]\n",
    "  print(f\"Number of time series in processed data {len(out_data)}\")\n",
    "  # write to disk\n",
    "  write_dicts_to_file(out_path, out_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 6.44 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# prepare_data(train_path, test_path, columns_to_skip, \n",
    "#              \"train.json\", \"st_fm.csv\",\n",
    "#              process_test = False, use_rows = 100000, min_day = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 6.44 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# prepare_data(train_path, test_path, columns_to_skip,\n",
    "#              \"test.json\", \"st_fm.csv\",\n",
    "#              process_test = True, use_rows = None, min_day = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "\n",
    "def copy_to_s3(local_file, s3_path, override=False):\n",
    "    assert s3_path.startswith(\"s3://\")\n",
    "    split = s3_path.split(\"/\")\n",
    "    bucket = split[2]\n",
    "    path = \"/\".join(split[3:])\n",
    "    buk = s3.Bucket(bucket)\n",
    "\n",
    "    if len(list(buk.objects.filter(Prefix=path))) > 0:\n",
    "        if not override:\n",
    "            print(\n",
    "                \"File s3://{}/{} already exists.\\nSet override to upload anyway.\\n\".format(\n",
    "                    s3_bucket, s3_path\n",
    "                )\n",
    "            )\n",
    "            return\n",
    "        else:\n",
    "            print(\"Overwriting existing file\")\n",
    "    with open(local_file, \"rb\") as data:\n",
    "        print(\"Uploading file to {}\".format(s3_path))\n",
    "        buk.put_object(Key=path, Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.72 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# copy_to_s3(\"train.json\", s3_data_path + \"/train/train.json\", override=True)\n",
    "# copy_to_s3(\"test.json\", s3_data_path + \"/test/test.json\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look to what we just wrote to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"start\": \"2017-07-10 00:00:00\", \"target\": [1.6094379124341003, 1.0986122886681096, 0.0, 1.098612288...\n"
     ]
    }
   ],
   "source": [
    "s3_sample = s3.Object(s3_bucket, s3_prefix + \"/data/train/train.json\").get()[\"Body\"].read()\n",
    "StringVariable = s3_sample.decode(\"UTF-8\", \"ignore\")\n",
    "lines = StringVariable.split(\"\\n\")\n",
    "print(lines[0][:100] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use 1 day frequency for the time series\n",
    "freq = \"D\"\n",
    "\n",
    "# we predict for 16 days\n",
    "prediction_length = 16\n",
    "\n",
    "# we can use 16 days as context length, this is the number of state updates accomplished before making predictions\n",
    "context_length = 25 #16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model\n",
    "\n",
    "Here we define the estimator that will launch the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "#     train_instance_type=\"ml.c4.2xlarge\",\n",
    "    train_instance_type=\"ml.m5.xlarge\",\n",
    "    use_spot_instances=True,\n",
    "    max_wait=3600,\n",
    "    max_run=3600,\n",
    "    base_job_name=\"deepar-exp\",\n",
    "    output_path=s3_output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to set the hyperparameters for the training job. For example frequency of the time series used, number of data points the model will look at in the past, number of predicted data points. The other hyperparameters concern the model to train (number of layers, number of cells per layer, likelihood function) and the training options (number of epochs, batch size, learning rate...). We use default parameters for every optional parameter in this case (we can always use [Sagemaker Automated Model Tuning](https://aws.amazon.com/blogs/aws/sagemaker-automatic-model-tuning/) to tune them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"197\", #\"100\", opt: \"197\"\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"mini_batch_size\": \"108\", #64, opt: 108\n",
    "    \"learning_rate\": \"0.000669277\", #5E-4, opt: 0.000669277\n",
    "    \"context_length\": str(context_length), # opt: 25\n",
    "    \"prediction_length\": str(prediction_length),\n",
    "}\n",
    "\n",
    "estimator.set_hyperparameters(**hyperparameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to launch the training job. SageMaker will start an EC2 instance, download the data from S3, start training the model and save the trained model.\n",
    "\n",
    "If we would have provided the `test` data channel then DeepAR will also calculate accuracy metrics for the trained model on this test. This is done by predicting the last `prediction_length` points of each time-series in the test set and comparing this to the actual value of the time-series. \n",
    "\n",
    "**Note:** the next cell may take a some time to complete, depending on data size, model complexity, training options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: deepar-exp-2023-04-24-22-20-55-488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-24 22:20:56 Starting - Starting the training job...\n",
      "2023-04-24 22:21:11 Starting - Preparing the instances for training...\n",
      "2023-04-24 22:21:58 Downloading - Downloading input data......\n",
      "2023-04-24 22:22:38 Training - Downloading the training image...\n",
      "2023-04-24 22:23:09 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34mRunning custom environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/jsonref.py:8: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, MutableMapping, Sequence\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:21 INFO 140561760122688] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:21 INFO 140561760122688] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '30', 'early_stopping_patience': '40', 'epochs': '200', 'learning_rate': '0.0005', 'mini_batch_size': '128', 'prediction_length': '16', 'time_freq': 'D'}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:21 INFO 140561760122688] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '40', 'embedding_dimension': '10', 'learning_rate': '0.0005', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '30', 'epochs': '200', 'prediction_length': '16', 'time_freq': 'D'}\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:21 INFO 140561760122688] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:22 INFO 140561760122688] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:22 INFO 140561760122688] random_seed is None\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:22 INFO 140561760122688] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:22 INFO 140561760122688] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:48 INFO 140561760122688] [cardinality=auto] Inferred value of cardinality=[54, 33, 5, 17, 22, 16] from dataset.\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:48 INFO 140561760122688] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=101 from dataset.\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:48 INFO 140561760122688] Training set statistics:\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:48 INFO 140561760122688] Real time series\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:48 INFO 140561760122688] number of time series: 1729\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:48 INFO 140561760122688] number of observations: 2155118\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:48 INFO 140561760122688] mean target length: 1246.4534412955466\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:48 INFO 140561760122688] min/mean/max target: 0.0/3.739640067851203/11.733810424804688\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:48 INFO 140561760122688] mean abs(target): 3.739640067851203\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:48 INFO 140561760122688] contains missing values: no\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:48 INFO 140561760122688] No test channel found not running evaluations\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/algorithm/core/date_feature_set.py:44: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
      "  return index.weekofyear / 51.0 - 0.5\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:48 INFO 140561760122688] #memory_usage::<batchbuffer> = 606.1572265625 mb\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:48 INFO 140561760122688] nvidia-smi: took 0.030 seconds to run.\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:48 INFO 140561760122688] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:48 INFO 140561760122688] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:48 INFO 140561760122688] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375028.073081, \"EndTime\": 1682375028.2009246, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 126.70516967773438, \"count\": 1, \"min\": 126.70516967773438, \"max\": 126.70516967773438}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:48 INFO 140561760122688] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:23:48 INFO 140561760122688] #memory_usage::<model> = 71 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375028.2010095, \"EndTime\": 1682375028.37764, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 304.4116497039795, \"count\": 1, \"min\": 304.4116497039795, \"max\": 304.4116497039795}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:09 INFO 140561760122688] Epoch[0] Batch[0] avg_epoch_loss=2.894207\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:09 INFO 140561760122688] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=2.894207000732422\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:10 INFO 140561760122688] Epoch[0] Batch[5] avg_epoch_loss=2.439568\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:10 INFO 140561760122688] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=2.4395675659179688\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:10 INFO 140561760122688] Epoch[0] Batch [5]#011Speed: 436.03 samples/sec#011loss=2.439568\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:18 INFO 140561760122688] Epoch[0] Batch[10] avg_epoch_loss=2.230128\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:18 INFO 140561760122688] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=1.9788005352020264\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:18 INFO 140561760122688] Epoch[0] Batch [10]#011Speed: 80.66 samples/sec#011loss=1.978801\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:19 INFO 140561760122688] processed a total of 1668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375028.3777056, \"EndTime\": 1682375059.6752381, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 200.0, \"count\": 1, \"min\": 200, \"max\": 200}, \"update.time\": {\"sum\": 31297.428846359253, \"count\": 1, \"min\": 31297.428846359253, \"max\": 31297.428846359253}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:19 INFO 140561760122688] #throughput_metric: host=algo-1, train throughput=53.29486634033342 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:19 INFO 140561760122688] #progress_metric: host=algo-1, completed 0.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:19 INFO 140561760122688] #quality_metric: host=algo-1, epoch=0, train loss <loss>=2.195471601826804\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:19 INFO 140561760122688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:19 INFO 140561760122688] Saved checkpoint to \"/opt/ml/model/state_05826032-7789-4966-a7a3-a986d55175df-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375059.6753273, \"EndTime\": 1682375059.6935081, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 17.574310302734375, \"count\": 1, \"min\": 17.574310302734375, \"max\": 17.574310302734375}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:39 INFO 140561760122688] Epoch[1] Batch[0] avg_epoch_loss=1.764828\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:39 INFO 140561760122688] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=1.764827847480774\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:41 INFO 140561760122688] Epoch[1] Batch[5] avg_epoch_loss=1.748461\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:41 INFO 140561760122688] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=1.748460829257965\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:41 INFO 140561760122688] Epoch[1] Batch [5]#011Speed: 524.80 samples/sec#011loss=1.748461\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:48 INFO 140561760122688] Epoch[1] Batch[10] avg_epoch_loss=1.738777\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:48 INFO 140561760122688] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=1.7271562099456788\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:48 INFO 140561760122688] Epoch[1] Batch [10]#011Speed: 82.24 samples/sec#011loss=1.727156\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:49 INFO 140561760122688] processed a total of 1713 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375059.693583, \"EndTime\": 1682375089.8683627, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 30174.71694946289, \"count\": 1, \"min\": 30174.71694946289, \"max\": 30174.71694946289}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:49 INFO 140561760122688] #throughput_metric: host=algo-1, train throughput=56.769188470838074 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:49 INFO 140561760122688] #progress_metric: host=algo-1, completed 1.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:49 INFO 140561760122688] #quality_metric: host=algo-1, epoch=1, train loss <loss>=1.7263396637780326\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:49 INFO 140561760122688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:24:49 INFO 140561760122688] Saved checkpoint to \"/opt/ml/model/state_926a6e70-540b-41c1-870f-cab3d12b92d1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375089.8684359, \"EndTime\": 1682375089.890989, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 22.188663482666016, \"count\": 1, \"min\": 22.188663482666016, \"max\": 22.188663482666016}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:08 INFO 140561760122688] Epoch[2] Batch[0] avg_epoch_loss=1.730167\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:08 INFO 140561760122688] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=1.7301666736602783\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:10 INFO 140561760122688] Epoch[2] Batch[5] avg_epoch_loss=1.607909\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:10 INFO 140561760122688] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=1.6079089641571045\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:10 INFO 140561760122688] Epoch[2] Batch [5]#011Speed: 522.68 samples/sec#011loss=1.607909\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:18 INFO 140561760122688] Epoch[2] Batch[10] avg_epoch_loss=1.586871\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:18 INFO 140561760122688] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=1.5616263628005982\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:18 INFO 140561760122688] Epoch[2] Batch [10]#011Speed: 71.78 samples/sec#011loss=1.561626\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:19 INFO 140561760122688] processed a total of 1774 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375089.8910615, \"EndTime\": 1682375119.9001749, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 30009.04607772827, \"count\": 1, \"min\": 30009.04607772827, \"max\": 30009.04607772827}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:19 INFO 140561760122688] #throughput_metric: host=algo-1, train throughput=59.11528620239751 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:19 INFO 140561760122688] #progress_metric: host=algo-1, completed 1.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:19 INFO 140561760122688] #quality_metric: host=algo-1, epoch=2, train loss <loss>=1.570771472794669\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:19 INFO 140561760122688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:19 INFO 140561760122688] Saved checkpoint to \"/opt/ml/model/state_686cf2fc-08b4-4e7c-8a15-5dfb9b960842-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375119.9002526, \"EndTime\": 1682375119.9181402, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 17.26531982421875, \"count\": 1, \"min\": 17.26531982421875, \"max\": 17.26531982421875}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:38 INFO 140561760122688] Epoch[3] Batch[0] avg_epoch_loss=1.590471\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:38 INFO 140561760122688] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=1.590470552444458\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:39 INFO 140561760122688] Epoch[3] Batch[5] avg_epoch_loss=1.522521\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:39 INFO 140561760122688] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=1.5225214163462322\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:39 INFO 140561760122688] Epoch[3] Batch [5]#011Speed: 529.56 samples/sec#011loss=1.522521\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:48 INFO 140561760122688] Epoch[3] Batch[10] avg_epoch_loss=1.504661\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:48 INFO 140561760122688] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=1.483228874206543\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:48 INFO 140561760122688] Epoch[3] Batch [10]#011Speed: 73.04 samples/sec#011loss=1.483229\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:49 INFO 140561760122688] processed a total of 1755 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375119.9183726, \"EndTime\": 1682375149.6663206, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29747.875690460205, \"count\": 1, \"min\": 29747.875690460205, \"max\": 29747.875690460205}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:49 INFO 140561760122688] #throughput_metric: host=algo-1, train throughput=58.995286782956654 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:49 INFO 140561760122688] #progress_metric: host=algo-1, completed 2.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:49 INFO 140561760122688] #quality_metric: host=algo-1, epoch=3, train loss <loss>=1.4658434987068176\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:49 INFO 140561760122688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:25:49 INFO 140561760122688] Saved checkpoint to \"/opt/ml/model/state_445c9ac1-c2dd-4d74-828c-489d10c26bc4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375149.6665483, \"EndTime\": 1682375149.684092, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 16.834259033203125, \"count\": 1, \"min\": 16.834259033203125, \"max\": 16.834259033203125}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:09 INFO 140561760122688] Epoch[4] Batch[0] avg_epoch_loss=1.356200\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:09 INFO 140561760122688] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=1.356199860572815\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:11 INFO 140561760122688] Epoch[4] Batch[5] avg_epoch_loss=1.378682\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:11 INFO 140561760122688] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=1.3786818385124207\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:11 INFO 140561760122688] Epoch[4] Batch [5]#011Speed: 438.02 samples/sec#011loss=1.378682\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:19 INFO 140561760122688] Epoch[4] Batch[10] avg_epoch_loss=1.337170\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:19 INFO 140561760122688] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=1.2873560667037964\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:19 INFO 140561760122688] Epoch[4] Batch [10]#011Speed: 78.10 samples/sec#011loss=1.287356\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:20 INFO 140561760122688] processed a total of 1740 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375149.684166, \"EndTime\": 1682375180.521498, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 30837.252616882324, \"count\": 1, \"min\": 30837.252616882324, \"max\": 30837.252616882324}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:20 INFO 140561760122688] #throughput_metric: host=algo-1, train throughput=56.42505071002383 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:20 INFO 140561760122688] #progress_metric: host=algo-1, completed 2.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:20 INFO 140561760122688] #quality_metric: host=algo-1, epoch=4, train loss <loss>=1.3202396631240845\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:20 INFO 140561760122688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:20 INFO 140561760122688] Saved checkpoint to \"/opt/ml/model/state_e7bf361c-0d07-43b2-a226-d9cfaf00c0d2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375180.5215662, \"EndTime\": 1682375180.5408328, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 18.799781799316406, \"count\": 1, \"min\": 18.799781799316406, \"max\": 18.799781799316406}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:39 INFO 140561760122688] Epoch[5] Batch[0] avg_epoch_loss=1.347003\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:39 INFO 140561760122688] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=1.3470033407211304\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:40 INFO 140561760122688] Epoch[5] Batch[5] avg_epoch_loss=1.214015\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:40 INFO 140561760122688] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=1.2140149871508281\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:40 INFO 140561760122688] Epoch[5] Batch [5]#011Speed: 515.31 samples/sec#011loss=1.214015\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:49 INFO 140561760122688] Epoch[5] Batch[10] avg_epoch_loss=1.204053\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:49 INFO 140561760122688] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=1.1920995473861695\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:49 INFO 140561760122688] Epoch[5] Batch [10]#011Speed: 75.79 samples/sec#011loss=1.192100\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:50 INFO 140561760122688] processed a total of 1752 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375180.5409048, \"EndTime\": 1682375210.270745, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29729.777812957764, \"count\": 1, \"min\": 29729.777812957764, \"max\": 29729.777812957764}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:50 INFO 140561760122688] #throughput_metric: host=algo-1, train throughput=58.93050753825448 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:50 INFO 140561760122688] #progress_metric: host=algo-1, completed 3.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:50 INFO 140561760122688] #quality_metric: host=algo-1, epoch=5, train loss <loss>=1.1742272675037384\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:50 INFO 140561760122688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:26:50 INFO 140561760122688] Saved checkpoint to \"/opt/ml/model/state_e1000156-d406-497d-bf63-ed571bc7e13c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375210.2708678, \"EndTime\": 1682375210.2936842, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 22.42565155029297, \"count\": 1, \"min\": 22.42565155029297, \"max\": 22.42565155029297}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:10 INFO 140561760122688] Epoch[6] Batch[0] avg_epoch_loss=1.112612\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:10 INFO 140561760122688] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=1.1126121282577515\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:11 INFO 140561760122688] Epoch[6] Batch[5] avg_epoch_loss=1.114103\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:11 INFO 140561760122688] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=1.1141034762064617\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:11 INFO 140561760122688] Epoch[6] Batch [5]#011Speed: 528.73 samples/sec#011loss=1.114103\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:19 INFO 140561760122688] Epoch[6] Batch[10] avg_epoch_loss=1.104298\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:19 INFO 140561760122688] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=1.0925308227539063\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:19 INFO 140561760122688] Epoch[6] Batch [10]#011Speed: 81.28 samples/sec#011loss=1.092531\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:20 INFO 140561760122688] processed a total of 1724 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375210.2937424, \"EndTime\": 1682375240.1836202, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29889.814615249634, \"count\": 1, \"min\": 29889.814615249634, \"max\": 29889.814615249634}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:20 INFO 140561760122688] #throughput_metric: host=algo-1, train throughput=57.67830300983858 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:20 INFO 140561760122688] #progress_metric: host=algo-1, completed 3.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:20 INFO 140561760122688] #quality_metric: host=algo-1, epoch=6, train loss <loss>=1.0816302682672227\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:20 INFO 140561760122688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:20 INFO 140561760122688] Saved checkpoint to \"/opt/ml/model/state_c70f28bf-3416-45f9-9de1-8705f9745bd4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375240.1836967, \"EndTime\": 1682375240.2072654, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 23.067235946655273, \"count\": 1, \"min\": 23.067235946655273, \"max\": 23.067235946655273}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:39 INFO 140561760122688] Epoch[7] Batch[0] avg_epoch_loss=1.020105\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:39 INFO 140561760122688] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=1.0201047658920288\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:41 INFO 140561760122688] Epoch[7] Batch[5] avg_epoch_loss=0.984505\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:41 INFO 140561760122688] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=0.9845045606295267\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:41 INFO 140561760122688] Epoch[7] Batch [5]#011Speed: 520.96 samples/sec#011loss=0.984505\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:49 INFO 140561760122688] Epoch[7] Batch[10] avg_epoch_loss=0.981107\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:49 INFO 140561760122688] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=0.9770289778709411\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:49 INFO 140561760122688] Epoch[7] Batch [10]#011Speed: 80.59 samples/sec#011loss=0.977029\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:49 INFO 140561760122688] processed a total of 1744 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375240.2073362, \"EndTime\": 1682375269.981089, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29773.68712425232, \"count\": 1, \"min\": 29773.68712425232, \"max\": 29773.68712425232}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:49 INFO 140561760122688] #throughput_metric: host=algo-1, train throughput=58.574997395506976 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:49 INFO 140561760122688] #progress_metric: host=algo-1, completed 4.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:49 INFO 140561760122688] #quality_metric: host=algo-1, epoch=7, train loss <loss>=0.9728825432913644\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:49 INFO 140561760122688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:27:49 INFO 140561760122688] Saved checkpoint to \"/opt/ml/model/state_7332a2ff-f788-4746-894f-0b0c9d011ead-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375269.9811637, \"EndTime\": 1682375269.9995043, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 17.84801483154297, \"count\": 1, \"min\": 17.84801483154297, \"max\": 17.84801483154297}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:10 INFO 140561760122688] Epoch[8] Batch[0] avg_epoch_loss=0.934377\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:10 INFO 140561760122688] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=0.9343765377998352\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:11 INFO 140561760122688] Epoch[8] Batch[5] avg_epoch_loss=0.949872\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:11 INFO 140561760122688] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=0.9498720864454905\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:11 INFO 140561760122688] Epoch[8] Batch [5]#011Speed: 532.54 samples/sec#011loss=0.949872\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:19 INFO 140561760122688] Epoch[8] Batch[10] avg_epoch_loss=0.928320\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:19 INFO 140561760122688] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=0.9024582147598267\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:19 INFO 140561760122688] Epoch[8] Batch [10]#011Speed: 85.09 samples/sec#011loss=0.902458\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:20 INFO 140561760122688] processed a total of 1687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375269.9995725, \"EndTime\": 1682375300.449792, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 30450.1531124115, \"count\": 1, \"min\": 30450.1531124115, \"max\": 30450.1531124115}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:20 INFO 140561760122688] #throughput_metric: host=algo-1, train throughput=55.401830273449235 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:20 INFO 140561760122688] #progress_metric: host=algo-1, completed 4.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:20 INFO 140561760122688] #quality_metric: host=algo-1, epoch=8, train loss <loss>=0.9138595674719129\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:20 INFO 140561760122688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:20 INFO 140561760122688] Saved checkpoint to \"/opt/ml/model/state_aa2f480e-acd0-465a-b83a-f89ef53b3ea7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375300.4498656, \"EndTime\": 1682375300.470374, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 19.901514053344727, \"count\": 1, \"min\": 19.901514053344727, \"max\": 19.901514053344727}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:41 INFO 140561760122688] Epoch[9] Batch[0] avg_epoch_loss=0.924014\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:41 INFO 140561760122688] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=0.9240142703056335\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:43 INFO 140561760122688] Epoch[9] Batch[5] avg_epoch_loss=0.897806\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:43 INFO 140561760122688] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=0.8978058199087778\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:43 INFO 140561760122688] Epoch[9] Batch [5]#011Speed: 506.21 samples/sec#011loss=0.897806\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:49 INFO 140561760122688] Epoch[9] Batch[10] avg_epoch_loss=0.888781\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:49 INFO 140561760122688] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=0.8779503345489502\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:49 INFO 140561760122688] Epoch[9] Batch [10]#011Speed: 96.18 samples/sec#011loss=0.877950\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:50 INFO 140561760122688] processed a total of 1644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375300.4704459, \"EndTime\": 1682375330.43904, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29968.52684020996, \"count\": 1, \"min\": 29968.52684020996, \"max\": 29968.52684020996}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:50 INFO 140561760122688] #throughput_metric: host=algo-1, train throughput=54.857355394509206 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:50 INFO 140561760122688] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:50 INFO 140561760122688] #quality_metric: host=algo-1, epoch=9, train loss <loss>=0.9038272362488967\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:50 INFO 140561760122688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:28:50 INFO 140561760122688] Saved checkpoint to \"/opt/ml/model/state_8c1358ba-9333-4477-9d51-5e686a4eab3f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375330.4391148, \"EndTime\": 1682375330.4605746, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 21.09217643737793, \"count\": 1, \"min\": 21.09217643737793, \"max\": 21.09217643737793}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:29:09 INFO 140561760122688] Epoch[10] Batch[0] avg_epoch_loss=0.895607\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:29:09 INFO 140561760122688] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=0.8956067562103271\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:29:10 INFO 140561760122688] Epoch[10] Batch[5] avg_epoch_loss=0.854621\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:29:10 INFO 140561760122688] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=0.8546208639939626\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:29:10 INFO 140561760122688] Epoch[10] Batch [5]#011Speed: 515.03 samples/sec#011loss=0.854621\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:29:19 INFO 140561760122688] Epoch[10] Batch[10] avg_epoch_loss=0.838947\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:29:19 INFO 140561760122688] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=0.8201383948326111\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:29:19 INFO 140561760122688] Epoch[10] Batch [10]#011Speed: 73.24 samples/sec#011loss=0.820138\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:29:20 INFO 140561760122688] processed a total of 1805 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375330.4606533, \"EndTime\": 1682375360.7663398, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 30305.620193481445, \"count\": 1, \"min\": 30305.620193481445, \"max\": 30305.620193481445}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:29:20 INFO 140561760122688] #throughput_metric: host=algo-1, train throughput=59.5596926844834 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:29:20 INFO 140561760122688] #progress_metric: host=algo-1, completed 5.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:29:20 INFO 140561760122688] #quality_metric: host=algo-1, epoch=10, train loss <loss>=0.8544538895289103\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:29:20 INFO 140561760122688] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[04/24/2023 22:29:20 INFO 140561760122688] Saved checkpoint to \"/opt/ml/model/state_2c552d88-ab8e-45b8-a3d7-618f417dd9a1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682375360.766416, \"EndTime\": 1682375360.7879813, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 21.00539207458496, \"count\": 1, \"min\": 21.00539207458496, \"max\": 21.00539207458496}}}\u001b[0m\n",
      "...........TRIMMED OUTPUTS MANUALLY.................",
      "\u001b[34m[04/24/2023 23:21:45 INFO 140561760122688] processed a total of 1746 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378475.437663, \"EndTime\": 1682378505.427942, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29989.760637283325, \"count\": 1, \"min\": 29989.760637283325, \"max\": 29989.760637283325}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:21:45 INFO 140561760122688] #throughput_metric: host=algo-1, train throughput=58.21965129399108 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:21:45 INFO 140561760122688] #progress_metric: host=algo-1, completed 58.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:21:45 INFO 140561760122688] #quality_metric: host=algo-1, epoch=115, train loss <loss>=0.36018125074250357\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:21:45 INFO 140561760122688] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:05 INFO 140561760122688] Epoch[116] Batch[0] avg_epoch_loss=0.318609\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:05 INFO 140561760122688] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=0.31860947608947754\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:06 INFO 140561760122688] Epoch[116] Batch[5] avg_epoch_loss=0.347210\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:06 INFO 140561760122688] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=0.3472096820672353\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:06 INFO 140561760122688] Epoch[116] Batch [5]#011Speed: 528.78 samples/sec#011loss=0.347210\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:14 INFO 140561760122688] Epoch[116] Batch[10] avg_epoch_loss=0.339101\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:14 INFO 140561760122688] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=0.32937073707580566\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:14 INFO 140561760122688] Epoch[116] Batch [10]#011Speed: 83.83 samples/sec#011loss=0.329371\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:15 INFO 140561760122688] processed a total of 1716 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378505.4280233, \"EndTime\": 1682378535.3777854, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 29949.411869049072, \"count\": 1, \"min\": 29949.411869049072, \"max\": 29949.411869049072}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:15 INFO 140561760122688] #throughput_metric: host=algo-1, train throughput=57.29640370621565 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:15 INFO 140561760122688] #progress_metric: host=algo-1, completed 58.5 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:15 INFO 140561760122688] #quality_metric: host=algo-1, epoch=116, train loss <loss>=0.3497318540300642\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:15 INFO 140561760122688] loss did not improve\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:36 INFO 140561760122688] Epoch[117] Batch[0] avg_epoch_loss=0.349071\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:36 INFO 140561760122688] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=0.34907060861587524\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:36 WARNING 140561760122688] Exit signal caught in epoch 117, batch 0. Skipping remaining batches in epoch.\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:36 INFO 140561760122688] processed a total of 128 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378535.3778636, \"EndTime\": 1682378556.603678, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 21225.23832321167, \"count\": 1, \"min\": 21225.23832321167, \"max\": 21225.23832321167}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:36 INFO 140561760122688] #throughput_metric: host=algo-1, train throughput=6.030528302789226 records/second\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:36 INFO 140561760122688] #progress_metric: host=algo-1, completed 59.0 % of epochs\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:36 INFO 140561760122688] #quality_metric: host=algo-1, epoch=117, train loss <loss>=0.34907060861587524\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:36 WARNING 140561760122688] Exit signal caught in epoch 117. Skipping remaining epochs.\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:36 INFO 140561760122688] Final loss: 0.3121088020769613 (occurred at epoch 113)\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:36 INFO 140561760122688] #quality_metric: host=algo-1, train final_loss <loss>=0.3121088020769613\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:36 INFO 140561760122688] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:36 WARNING 140561760122688] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:36 INFO 140561760122688] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378556.6037433, \"EndTime\": 1682378556.8117058, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 207.06439018249512, \"count\": 1, \"min\": 207.06439018249512, \"max\": 207.06439018249512}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:36 INFO 140561760122688] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378556.8117769, \"EndTime\": 1682378556.8775082, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 273.0581760406494, \"count\": 1, \"min\": 273.0581760406494, \"max\": 273.0581760406494}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:36 INFO 140561760122688] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:36 INFO 140561760122688] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378556.8775752, \"EndTime\": 1682378556.8902268, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 12.61138916015625, \"count\": 1, \"min\": 12.61138916015625, \"max\": 12.61138916015625}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:36 INFO 140561760122688] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:22:36 INFO 140561760122688] No test data passed, skipping evaluation.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378556.8902805, \"EndTime\": 1682378556.9092426, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 5.6896209716796875, \"count\": 1, \"min\": 5.6896209716796875, \"max\": 5.6896209716796875}, \"totaltime\": {\"sum\": 3555012.417793274, \"count\": 1, \"min\": 3555012.417793274, \"max\": 3555012.417793274}}}\u001b[0m\n",
      "\n",
      "2023-04-24 23:22:52 Stopping - Stopping the training job\n",
      "2023-04-24 23:22:52 Uploading - Uploading generated training model\n",
      "2023-04-24 23:22:52 MaxRuntimeExceeded - Training job runtime exceeded MaxRuntimeInSeconds provided\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Job ended with status 'Stopped' rather than 'Completed'. This could mean the job timed out or stopped early for some other reason: Consider checking whether it completed as you expect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 3641\n",
      "Billable seconds: 2206\n",
      "Managed Spot Training savings: 39.4%\n",
      "CPU times: user 20.9 s, sys: 456 ms, total: 21.4 s\n",
      "Wall time: 1h 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data_channels = {\"train\": \"{}/train/\".format(s3_data_path), \"test\": \"{}/test/\".format(s3_data_path)}\n",
    "data_channels = {\"train\": \"{}/train/\".format(s3_data_path)}\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch Transform** using `estimator.transformer`, high level sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepar-exp-2023-04-24-22-20-55-488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.analytics:Warning: No metrics called test:mean_wQuantileLoss found\n",
      "WARNING:sagemaker.analytics:Warning: No metrics called test:RMSE found\n"
     ]
    }
   ],
   "source": [
    "job_name = estimator.latest_training_job.name\n",
    "print(job_name)\n",
    "estimator.training_job_analytics.export_csv(\"training_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: deepar-exp-2023-04-24-23-23-08-361\n",
      "INFO:sagemaker:Creating transform job with name: deepar-exp-2023-04-24-23-23-08-959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34mRunning custom environment configuration script\u001b[0m\n",
      "\u001b[34mFailed to set debug level to 20, using INFO\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:29:16 INFO 139978782734144] Estimated memory required per model 15.984892845153809MB.\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:29:16 INFO 139978782734144] Estimated available memory 14941.698183059692MB.\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:29:16 INFO 139978782734144] Estimated maximum number of workers for the available memory is 934.\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:29:16 INFO 139978782734144] Using 4 workers\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:29:16 INFO 139978782734144] loading entry points\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:29:16 INFO 139978782734144] Prediction endpoint operating in batch mode\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:29:16 INFO 139978782734144] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:29:16 INFO 139978782734144] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:29:16 INFO 139978782734144] loaded model class model\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:29:16 WARNING 139978782734144] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:29:16 INFO 139978782734144] nvidia-smi: took 0.030 seconds to run.\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:29:16 INFO 139978782734144] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:29:16 INFO 139978782734144] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:29:16 INFO 139978782734144] Loading Config from /opt/ml/model/model_algo-1-config.json\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/algorithm/core/date_feature_set.py:44: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
      "  return index.weekofyear / 51.0 - 0.5\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378956.6994634, \"EndTime\": 1682378956.87843, \"Dimensions\": {}, \"Metrics\": {\"model.deserialize_phase1.time\": {\"sum\": 13.763427734375, \"count\": 1, \"min\": 13.763427734375, \"max\": 13.763427734375}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:29:16 INFO 139978782734144] Deserializing model parameters from /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[23:29:16] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.208080.0/AL2_x86_64/generic-flavor/src/src/engine/engine.cc:55: MXNet start using engine: NaiveEngine\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378956.878626, \"EndTime\": 1682378956.9797988, \"Dimensions\": {}, \"Metrics\": {\"model.bind.time\": {\"sum\": 57.152748107910156, \"count\": 1, \"min\": 57.152748107910156, \"max\": 57.152748107910156}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378956.9798882, \"EndTime\": 1682378956.9799175, \"Dimensions\": {}, \"Metrics\": {\"model.deserialize_phase2.time\": {\"sum\": 101.26090049743652, \"count\": 1, \"min\": 101.26090049743652, \"max\": 101.26090049743652}}}\u001b[0m\n",
      "\u001b[34m[2023-04-24 23:29:17 +0000] [1] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2023-04-24 23:29:17 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2023-04-24 23:29:17 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2023-04-24 23:29:17 +0000] [32] [INFO] Booting worker with pid: 32\u001b[0m\n",
      "\u001b[34m[2023-04-24 23:29:17 +0000] [33] [INFO] Booting worker with pid: 33\u001b[0m\n",
      "\u001b[34m[2023-04-24 23:29:17 +0000] [34] [INFO] Booting worker with pid: 34\u001b[0m\n",
      "\u001b[34m[2023-04-24 23:29:17 +0000] [35] [INFO] Booting worker with pid: 35\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:29:23 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378957.1059213, \"EndTime\": 1682378963.2733903, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.102996826171875, \"count\": 1, \"min\": 0.102996826171875, \"max\": 0.102996826171875}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:29:23 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378957.1362069, \"EndTime\": 1682378963.277779, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.09751319885253906, \"count\": 1, \"min\": 0.09751319885253906, \"max\": 0.09751319885253906}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:29:23 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378957.2199152, \"EndTime\": 1682378963.2805986, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.09894371032714844, \"count\": 1, \"min\": 0.09894371032714844, \"max\": 0.09894371032714844}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:29:23 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378957.0259337, \"EndTime\": 1682378963.2825136, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.20384788513183594, \"count\": 1, \"min\": 0.20384788513183594, \"max\": 0.20384788513183594}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378963.273548, \"EndTime\": 1682378963.378754, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.08368492126464844, \"count\": 1, \"min\": 0.08368492126464844, \"max\": 0.08368492126464844}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378963.2810328, \"EndTime\": 1682378963.3788903, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.06341934204101562, \"count\": 1, \"min\": 0.06341934204101562, \"max\": 0.06341934204101562}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378963.3790154, \"EndTime\": 1682378963.3799741, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378963.379675, \"EndTime\": 1682378963.3806586, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378963.2779202, \"EndTime\": 1682378963.3868926, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.0762939453125, \"count\": 1, \"min\": 0.0762939453125, \"max\": 0.0762939453125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378963.3870087, \"EndTime\": 1682378963.387682, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378963.282635, \"EndTime\": 1682378963.388993, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.06628036499023438, \"count\": 1, \"min\": 0.06628036499023438, \"max\": 0.06628036499023438}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682378963.3890953, \"EndTime\": 1682378963.3897214, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m[04/24/2023 23:29:23 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682378957.1059213, \"EndTime\": 1682378963.2733903, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.102996826171875, \"count\": 1, \"min\": 0.102996826171875, \"max\": 0.102996826171875}}}\u001b[0m\n",
      "\u001b[35m[04/24/2023 23:29:23 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682378957.1362069, \"EndTime\": 1682378963.277779, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.09751319885253906, \"count\": 1, \"min\": 0.09751319885253906, \"max\": 0.09751319885253906}}}\u001b[0m\n",
      "...........TRIMMED OUTPUTS MANUALLY.................",
      "\u001b[35m[04/24/2023 23:38:03 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379482.310517, \"EndTime\": 1682379483.819728, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.033855438232421875, \"count\": 1, \"min\": 0.033855438232421875, \"max\": 0.033855438232421875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379483.8198183, \"EndTime\": 1682379483.8991797, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.07677078247070312, \"count\": 1, \"min\": 0.07677078247070312, \"max\": 0.07677078247070312}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379483.899293, \"EndTime\": 1682379483.9007788, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:38:04 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379482.8867135, \"EndTime\": 1682379484.379876, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.032901763916015625, \"count\": 1, \"min\": 0.032901763916015625, \"max\": 0.032901763916015625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379484.3804219, \"EndTime\": 1682379484.459022, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.06580352783203125, \"count\": 1, \"min\": 0.06580352783203125, \"max\": 0.06580352783203125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379484.4596019, \"EndTime\": 1682379484.4611256, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379483.8198183, \"EndTime\": 1682379483.8991797, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.07677078247070312, \"count\": 1, \"min\": 0.07677078247070312, \"max\": 0.07677078247070312}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379483.899293, \"EndTime\": 1682379483.9007788, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m[04/24/2023 23:38:04 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379482.8867135, \"EndTime\": 1682379484.379876, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.032901763916015625, \"count\": 1, \"min\": 0.032901763916015625, \"max\": 0.032901763916015625}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379484.3804219, \"EndTime\": 1682379484.459022, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.06580352783203125, \"count\": 1, \"min\": 0.06580352783203125, \"max\": 0.06580352783203125}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379484.4596019, \"EndTime\": 1682379484.4611256, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:38:04 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379483.4277515, \"EndTime\": 1682379484.9480329, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.03147125244140625, \"count\": 1, \"min\": 0.03147125244140625, \"max\": 0.03147125244140625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379484.9481232, \"EndTime\": 1682379485.0267158, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.07557868957519531, \"count\": 1, \"min\": 0.07557868957519531, \"max\": 0.07557868957519531}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379485.0268285, \"EndTime\": 1682379485.0283034, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:38:05 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379483.4959145, \"EndTime\": 1682379485.0423286, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0324249267578125, \"count\": 1, \"min\": 0.0324249267578125, \"max\": 0.0324249267578125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379485.042416, \"EndTime\": 1682379485.1202905, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.07295608520507812, \"count\": 1, \"min\": 0.07295608520507812, \"max\": 0.07295608520507812}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379485.12046, \"EndTime\": 1682379485.121997, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:38:05 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379483.9008577, \"EndTime\": 1682379485.3963714, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.03552436828613281, \"count\": 1, \"min\": 0.03552436828613281, \"max\": 0.03552436828613281}}}\u001b[0m\n",
      "\u001b[35m[04/24/2023 23:38:04 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379483.4277515, \"EndTime\": 1682379484.9480329, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.03147125244140625, \"count\": 1, \"min\": 0.03147125244140625, \"max\": 0.03147125244140625}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379484.9481232, \"EndTime\": 1682379485.0267158, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.07557868957519531, \"count\": 1, \"min\": 0.07557868957519531, \"max\": 0.07557868957519531}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379485.0268285, \"EndTime\": 1682379485.0283034, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m[04/24/2023 23:38:05 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379483.4959145, \"EndTime\": 1682379485.0423286, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0324249267578125, \"count\": 1, \"min\": 0.0324249267578125, \"max\": 0.0324249267578125}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379485.042416, \"EndTime\": 1682379485.1202905, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.07295608520507812, \"count\": 1, \"min\": 0.07295608520507812, \"max\": 0.07295608520507812}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379485.12046, \"EndTime\": 1682379485.121997, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m[04/24/2023 23:38:05 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379483.9008577, \"EndTime\": 1682379485.3963714, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.03552436828613281, \"count\": 1, \"min\": 0.03552436828613281, \"max\": 0.03552436828613281}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379485.396468, \"EndTime\": 1682379485.4752622, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.07581710815429688, \"count\": 1, \"min\": 0.07581710815429688, \"max\": 0.07581710815429688}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379485.4753673, \"EndTime\": 1682379485.4768982, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379485.396468, \"EndTime\": 1682379485.4752622, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.07581710815429688, \"count\": 1, \"min\": 0.07581710815429688, \"max\": 0.07581710815429688}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379485.4753673, \"EndTime\": 1682379485.4768982, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:38:05 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379484.4616315, \"EndTime\": 1682379485.965082, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.03409385681152344, \"count\": 1, \"min\": 0.03409385681152344, \"max\": 0.03409385681152344}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379485.9656076, \"EndTime\": 1682379486.0446444, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.0762939453125, \"count\": 1, \"min\": 0.0762939453125, \"max\": 0.0762939453125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379486.0454226, \"EndTime\": 1682379486.0470283, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:38:06 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379485.028387, \"EndTime\": 1682379486.5273314, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.03147125244140625, \"count\": 1, \"min\": 0.03147125244140625, \"max\": 0.03147125244140625}}}\u001b[0m\n",
      "\u001b[35m[04/24/2023 23:38:05 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379484.4616315, \"EndTime\": 1682379485.965082, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.03409385681152344, \"count\": 1, \"min\": 0.03409385681152344, \"max\": 0.03409385681152344}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379485.9656076, \"EndTime\": 1682379486.0446444, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.0762939453125, \"count\": 1, \"min\": 0.0762939453125, \"max\": 0.0762939453125}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379486.0454226, \"EndTime\": 1682379486.0470283, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m[04/24/2023 23:38:06 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379485.028387, \"EndTime\": 1682379486.5273314, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.03147125244140625, \"count\": 1, \"min\": 0.03147125244140625, \"max\": 0.03147125244140625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379486.527423, \"EndTime\": 1682379486.606833, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.0782012939453125, \"count\": 1, \"min\": 0.0782012939453125, \"max\": 0.0782012939453125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379486.6069546, \"EndTime\": 1682379486.6084836, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:38:06 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379485.1220722, \"EndTime\": 1682379486.6274717, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.03314018249511719, \"count\": 1, \"min\": 0.03314018249511719, \"max\": 0.03314018249511719}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379486.6275613, \"EndTime\": 1682379486.6744843, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.04267692565917969, \"count\": 1, \"min\": 0.04267692565917969, \"max\": 0.04267692565917969}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379486.6745527, \"EndTime\": 1682379486.675793, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379486.527423, \"EndTime\": 1682379486.606833, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.0782012939453125, \"count\": 1, \"min\": 0.0782012939453125, \"max\": 0.0782012939453125}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379486.6069546, \"EndTime\": 1682379486.6084836, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m[04/24/2023 23:38:06 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379485.1220722, \"EndTime\": 1682379486.6274717, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.03314018249511719, \"count\": 1, \"min\": 0.03314018249511719, \"max\": 0.03314018249511719}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379486.6275613, \"EndTime\": 1682379486.6744843, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.04267692565917969, \"count\": 1, \"min\": 0.04267692565917969, \"max\": 0.04267692565917969}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379486.6745527, \"EndTime\": 1682379486.675793, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:38:06 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379485.476976, \"EndTime\": 1682379486.8618782, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0362396240234375, \"count\": 1, \"min\": 0.0362396240234375, \"max\": 0.0362396240234375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379486.8619788, \"EndTime\": 1682379486.9128935, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.05125999450683594, \"count\": 1, \"min\": 0.05125999450683594, \"max\": 0.05125999450683594}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379486.912971, \"EndTime\": 1682379486.9141197, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m[04/24/2023 23:38:07 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379486.0475545, \"EndTime\": 1682379487.153851, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.03361701965332031, \"count\": 1, \"min\": 0.03361701965332031, \"max\": 0.03361701965332031}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379487.1539443, \"EndTime\": 1682379487.2004442, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.05054473876953125, \"count\": 1, \"min\": 0.05054473876953125, \"max\": 0.05054473876953125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1682379487.200532, \"EndTime\": 1682379487.201849, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m[04/24/2023 23:38:06 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379485.476976, \"EndTime\": 1682379486.8618782, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.0362396240234375, \"count\": 1, \"min\": 0.0362396240234375, \"max\": 0.0362396240234375}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379486.8619788, \"EndTime\": 1682379486.9128935, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.05125999450683594, \"count\": 1, \"min\": 0.05125999450683594, \"max\": 0.05125999450683594}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379486.912971, \"EndTime\": 1682379486.9141197, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m[04/24/2023 23:38:07 INFO 139978782734144] #memory_usage::<batchbuffer> = 4.734382629394531 mb\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379486.0475545, \"EndTime\": 1682379487.153851, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"model.evaluate.time\": {\"sum\": 0.03361701965332031, \"count\": 1, \"min\": 0.03361701965332031, \"max\": 0.03361701965332031}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379487.1539443, \"EndTime\": 1682379487.2004442, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"serve.jsonlines_encoder.time\": {\"sum\": 0.05054473876953125, \"count\": 1, \"min\": 0.05054473876953125, \"max\": 0.05054473876953125}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1682379487.200532, \"EndTime\": 1682379487.201849, \"Dimensions\": {\"Algorithm\": \"DeepARModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "CPU times: user 5.85 s, sys: 243 ms, total: 6.09 s\n",
      "Wall time: 15min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# ---- Use below if want to reuse prexisting training job -----\n",
    "# estimator = sagemaker.estimator.Estimator.attach(\"deepar-exp-2023-04-24-01-12-58-190\")\n",
    "\n",
    "deepar_transformer = estimator.transformer(\n",
    "    instance_count=1,\n",
    "#     instance_type=\"ml.c5.9xlarge\",\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    output_path=\"s3://{}/{}/transform\".format(s3_bucket, s3_prefix),\n",
    "    strategy=\"SingleRecord\",\n",
    "    assemble_with=\"Line\",\n",
    ")\n",
    "deepar_transformer.transform(\n",
    "    data = s3_data_path + \"/test/test.json\", content_type=\"application/jsonlines\", split_type=\"Line\",\n",
    "#     join_source = \"Input\"\n",
    ")\n",
    "deepar_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's look at the output of batch transform!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"mean\":[2.8673315048,2.3319144249,2.2663228512,2.2955989838,2.2561569214,2.375431776,2.5436377525,2.7615175247,2.7619309425,3.0046942234,3.019310236,3.0666129589,3.2672317028,3.0390007496,3.3445601463,3.2858316898],\"quantiles\":{\"0.1\":[1.5224021673,1.3472399712,1.2359864712,1.1427799463,1.146871686,1.1890159845,1.363530159,1.5294101238,1.4539458752,1.7713561058,1.4912682772,1.5076121092,1.6815936565,1.6383969784,1.9736554623,1.8269717693],\"0.2\":[2.0961575508,1.7298599482,1.6315221786,1.508690357...\n"
     ]
    }
   ],
   "source": [
    "s3_sample = s3.Object(s3_bucket, s3_prefix + \"/transform/test.json.out\").get()[\"Body\"].read()\n",
    "StringVariable = s3_sample.decode(\"UTF-8\", \"ignore\")\n",
    "lines = StringVariable.split(\"\\n\")\n",
    "print(lines[0][:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>st_fm_index</th>\n",
       "      <th>period</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.583222</td>\n",
       "      <td>17.660732</td>\n",
       "      <td>63.671560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.922411</td>\n",
       "      <td>24.449983</td>\n",
       "      <td>108.082121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.426658</td>\n",
       "      <td>22.656217</td>\n",
       "      <td>86.585022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.955716</td>\n",
       "      <td>9.645138</td>\n",
       "      <td>32.705269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.682634</td>\n",
       "      <td>14.355573</td>\n",
       "      <td>62.049729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28507</th>\n",
       "      <td>1777</td>\n",
       "      <td>15</td>\n",
       "      <td>110.548919</td>\n",
       "      <td>206.365049</td>\n",
       "      <td>564.710685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28508</th>\n",
       "      <td>1778</td>\n",
       "      <td>15</td>\n",
       "      <td>121.838461</td>\n",
       "      <td>161.098070</td>\n",
       "      <td>252.796287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28509</th>\n",
       "      <td>1779</td>\n",
       "      <td>15</td>\n",
       "      <td>60.474930</td>\n",
       "      <td>85.147618</td>\n",
       "      <td>134.012823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28510</th>\n",
       "      <td>1780</td>\n",
       "      <td>15</td>\n",
       "      <td>44.812384</td>\n",
       "      <td>71.261815</td>\n",
       "      <td>114.303210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28511</th>\n",
       "      <td>1781</td>\n",
       "      <td>15</td>\n",
       "      <td>21.672860</td>\n",
       "      <td>31.419876</td>\n",
       "      <td>45.159752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28512 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       st_fm_index  period         0.1         0.5         0.9\n",
       "0                0       0    3.583222   17.660732   63.671560\n",
       "1                1       0    3.922411   24.449983  108.082121\n",
       "2                2       0    4.426658   22.656217   86.585022\n",
       "3                3       0    1.955716    9.645138   32.705269\n",
       "4                4       0    1.682634   14.355573   62.049729\n",
       "...            ...     ...         ...         ...         ...\n",
       "28507         1777      15  110.548919  206.365049  564.710685\n",
       "28508         1778      15  121.838461  161.098070  252.796287\n",
       "28509         1779      15   60.474930   85.147618  134.012823\n",
       "28510         1780      15   44.812384   71.261815  114.303210\n",
       "28511         1781      15   21.672860   31.419876   45.159752\n",
       "\n",
       "[28512 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# json.loads(StringVariable.split(\"\\n\")[0])\n",
    "\n",
    "# Extract 10, 50 and 90th percentile forecast\n",
    "\n",
    "qs = ['0.1', '0.5', '0.9']\n",
    "\n",
    "predictions = (\n",
    "    pd.melt(\n",
    "        pd.DataFrame([json.loads(l)['quantiles'][qs[0]] for l in StringVariable.splitlines()]),\n",
    "        var_name='period', value_name=qs[0], ignore_index=False\n",
    "    )\n",
    "    .reset_index()\n",
    "    .merge(\n",
    "        pd.melt(\n",
    "            pd.DataFrame([json.loads(l)['quantiles'][qs[1]] for l in StringVariable.splitlines()]),\n",
    "            var_name='period', value_name=qs[1], ignore_index=False\n",
    "        )\n",
    "        .reset_index(),\n",
    "        on = ['index', 'period']\n",
    "    )\n",
    "    .merge(\n",
    "        pd.melt(\n",
    "            pd.DataFrame([json.loads(l)['quantiles'][qs[2]] for l in StringVariable.splitlines()]),\n",
    "            var_name='period', value_name=qs[2], ignore_index=False\n",
    "        )\n",
    "        .reset_index(),\n",
    "        on = ['index', 'period']\n",
    "    )\n",
    "    .rename(columns = {'index': 'st_fm_index'})\n",
    ")\n",
    "\n",
    "# Reverse log1p transformation on sales\n",
    "predictions['0.1'] = np.exp(predictions['0.1']) - 1\n",
    "predictions['0.5'] = np.exp(predictions['0.5']) - 1\n",
    "predictions['0.9'] = np.exp(predictions['0.9']) - 1\n",
    "\n",
    "predictions[predictions < 0] = 0\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>st_fm_index</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>BOOKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>BOOKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>BOOKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>BOOKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>1777</td>\n",
       "      <td>25</td>\n",
       "      <td>LIQUOR,WINE,BEER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>1778</td>\n",
       "      <td>25</td>\n",
       "      <td>MEATS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>1779</td>\n",
       "      <td>25</td>\n",
       "      <td>PERSONAL CARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>1780</td>\n",
       "      <td>25</td>\n",
       "      <td>FROZEN FOODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>1781</td>\n",
       "      <td>25</td>\n",
       "      <td>PREPARED FOODS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1782 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      st_fm_index  store_nbr            family\n",
       "0               0         40             BOOKS\n",
       "1               1         30             BOOKS\n",
       "2               2         17             BOOKS\n",
       "3               3          1         BABY CARE\n",
       "4               4         43             BOOKS\n",
       "...           ...        ...               ...\n",
       "1777         1777         25  LIQUOR,WINE,BEER\n",
       "1778         1778         25             MEATS\n",
       "1779         1779         25     PERSONAL CARE\n",
       "1780         1780         25      FROZEN FOODS\n",
       "1781         1781         25    PREPARED FOODS\n",
       "\n",
       "[1782 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the store and family details based on the store-family index\n",
    "# This is to identify the correct order of the predicted data\n",
    "st_fm_index = (\n",
    "    pd.read_csv(\"st_fm.csv\", index_col=0)\n",
    "    .reset_index()\n",
    "    .rename(columns = {'index': 'st_fm_index'})\n",
    "    .drop(columns=['days'])\n",
    ")\n",
    "st_fm_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>st_fm_index</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>period</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0</td>\n",
       "      <td>3.583222</td>\n",
       "      <td>17.660732</td>\n",
       "      <td>63.671560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>1</td>\n",
       "      <td>2.846794</td>\n",
       "      <td>10.154344</td>\n",
       "      <td>21.873889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>2</td>\n",
       "      <td>2.441772</td>\n",
       "      <td>7.531136</td>\n",
       "      <td>29.325595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>3</td>\n",
       "      <td>2.135473</td>\n",
       "      <td>9.015605</td>\n",
       "      <td>23.382294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>4</td>\n",
       "      <td>2.148329</td>\n",
       "      <td>8.647682</td>\n",
       "      <td>30.238159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28507</th>\n",
       "      <td>1781</td>\n",
       "      <td>25</td>\n",
       "      <td>PREPARED FOODS</td>\n",
       "      <td>11</td>\n",
       "      <td>29.792719</td>\n",
       "      <td>46.261498</td>\n",
       "      <td>75.335735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28508</th>\n",
       "      <td>1781</td>\n",
       "      <td>25</td>\n",
       "      <td>PREPARED FOODS</td>\n",
       "      <td>12</td>\n",
       "      <td>25.178310</td>\n",
       "      <td>33.686935</td>\n",
       "      <td>57.368467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28509</th>\n",
       "      <td>1781</td>\n",
       "      <td>25</td>\n",
       "      <td>PREPARED FOODS</td>\n",
       "      <td>13</td>\n",
       "      <td>16.702669</td>\n",
       "      <td>27.035960</td>\n",
       "      <td>43.530136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28510</th>\n",
       "      <td>1781</td>\n",
       "      <td>25</td>\n",
       "      <td>PREPARED FOODS</td>\n",
       "      <td>14</td>\n",
       "      <td>22.288656</td>\n",
       "      <td>33.257516</td>\n",
       "      <td>47.831939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28511</th>\n",
       "      <td>1781</td>\n",
       "      <td>25</td>\n",
       "      <td>PREPARED FOODS</td>\n",
       "      <td>15</td>\n",
       "      <td>21.672860</td>\n",
       "      <td>31.419876</td>\n",
       "      <td>45.159752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28512 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       st_fm_index  store_nbr          family  period        0.1        0.5  \\\n",
       "0                0         40           BOOKS       0   3.583222  17.660732   \n",
       "1                0         40           BOOKS       1   2.846794  10.154344   \n",
       "2                0         40           BOOKS       2   2.441772   7.531136   \n",
       "3                0         40           BOOKS       3   2.135473   9.015605   \n",
       "4                0         40           BOOKS       4   2.148329   8.647682   \n",
       "...            ...        ...             ...     ...        ...        ...   \n",
       "28507         1781         25  PREPARED FOODS      11  29.792719  46.261498   \n",
       "28508         1781         25  PREPARED FOODS      12  25.178310  33.686935   \n",
       "28509         1781         25  PREPARED FOODS      13  16.702669  27.035960   \n",
       "28510         1781         25  PREPARED FOODS      14  22.288656  33.257516   \n",
       "28511         1781         25  PREPARED FOODS      15  21.672860  31.419876   \n",
       "\n",
       "             0.9  \n",
       "0      63.671560  \n",
       "1      21.873889  \n",
       "2      29.325595  \n",
       "3      23.382294  \n",
       "4      30.238159  \n",
       "...          ...  \n",
       "28507  75.335735  \n",
       "28508  57.368467  \n",
       "28509  43.530136  \n",
       "28510  47.831939  \n",
       "28511  45.159752  \n",
       "\n",
       "[28512 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the store-family index with prediction\n",
    "final_predictions = st_fm_index.merge(predictions, on=['st_fm_index']).sort_values(by=['st_fm_index', 'period'])\n",
    "\n",
    "final_predictions.to_csv(\"deep_pred.csv\")\n",
    "\n",
    "final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Autotuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "# epochs (1-1000, 100), context_length (1-200, 16), mini_batch_size (32-1028, 64)\n",
    "# learning_rate (10^-5 to 10^-1, 5*10^-4), and num_cells (30-200, 40)\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"epochs\": IntegerParameter(100, 200),\n",
    "    \"context_length\": IntegerParameter(16, 30),\n",
    "    \"mini_batch_size\": IntegerParameter(64, 128),\n",
    "    \"learning_rate\": ContinuousParameter(0.0005, 0.001),\n",
    "}\n",
    "\n",
    "objective_metric_name = \"train:final_loss\" # test:RMSE\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    objective_type=\"Minimize\",\n",
    "    max_jobs=5,\n",
    "    max_parallel_jobs=2,\n",
    "    early_stopping_type =\"Auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can launch a hyperparameter tuning job by calling fit in tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating hyperparameter tuning job with name: forecasting-deepar-230423-2226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "tuner.fit(\n",
    "    {\"train\": \"{}/train/\".format(s3_data_path)},\n",
    "    include_cls_metadata=False,\n",
    ")\n",
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the tuning finished, the top 5 performing hyperparameters can be listed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tuner.latest_tuning_job.job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stopped'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3_sm.describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=\"forecasting-deepar-230423-2226\"#tuner.latest_tuning_job.job_name\n",
    ")[\"HyperParameterTuningJobStatus\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner_metrics = sagemaker.HyperparameterTuningJobAnalytics(tuner.latest_tuning_job.job_name)\n",
    "# tuner_metrics.dataframe().sort_values([\"FinalObjectiveValue\"], ascending=True).head(5)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
